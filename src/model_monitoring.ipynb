{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4230aaff",
   "metadata": {},
   "source": [
    "# Model Monitoring - Data Drift Detection\n",
    "\n",
    "## Objetivo\n",
    "Detectar cambios en la distribuci√≥n de datos (Data Drift) que puedan afectar el desempe√±o del modelo en producci√≥n.\n",
    "\n",
    "## Componentes\n",
    "- **Tests Estad√≠sticos**: KS test, PSI, Jensen-Shannon divergence, Chi-cuadrado\n",
    "- **Visualizaciones**: Comparaci√≥n de distribuciones hist√≥ricas vs actuales\n",
    "- **Sistema de Alertas**: Umbrales cr√≠ticos y recomendaciones de retraining\n",
    "- **Dashboard Streamlit**: Visualizaci√≥n interactiva de m√©tricas de drift\n",
    "\n",
    "---\n",
    "**Autor**: MLOps Pipeline Project  \n",
    "**Fecha**: Noviembre 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ad0805",
   "metadata": {},
   "source": [
    "## 1. Imports y Configuraci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9cc27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports principales\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import joblib\n",
    "\n",
    "# Visualizaci√≥n\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Tests estad√≠sticos\n",
    "from scipy import stats\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "from scipy.stats import ks_2samp, chi2_contingency\n",
    "\n",
    "# Evidently para drift detection\n",
    "from evidently.report import Report\n",
    "from evidently.metric_preset import DataDriftPreset, DataQualityPreset\n",
    "from evidently.metrics import *\n",
    "\n",
    "# Feature Engineering\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from ft_engineering import prepare_data_for_training\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuraci√≥n de visualizaci√≥n\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"‚úì Librer√≠as importadas correctamente\")\n",
    "print(f\"Fecha de ejecuci√≥n: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6192a1",
   "metadata": {},
   "source": [
    "## 2. Cargar Configuraci√≥n del Proyecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8089b597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar configuraci√≥n\n",
    "with open('../config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"CONFIGURACI√ìN DEL PROYECTO\")\n",
    "print(\"=\" * 80)\n",
    "for key, value in config.items():\n",
    "    print(f\"{key:20s}: {value}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Directorios\n",
    "MODEL_OUTPUT_DIR = f\"../{config.get('model_output_dir', 'models/')}\"\n",
    "MONITORING_DIR = '../monitoring_reports/'\n",
    "os.makedirs(MONITORING_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"\\n‚úì Directorio de reportes creado: {MONITORING_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb718bd",
   "metadata": {},
   "source": [
    "## 3. Cargar Datos de Referencia (Training Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8d0a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos de entrenamiento como referencia (baseline)\n",
    "X_train, X_test, y_train, y_test, preprocessor, feature_names = prepare_data_for_training(\n",
    "    config_path='../config.json',\n",
    "    test_size=0.2,\n",
    "    save_preprocessor=False\n",
    ")\n",
    "\n",
    "# Convertir a DataFrame para an√°lisis\n",
    "reference_data = pd.DataFrame(X_train, columns=feature_names)\n",
    "reference_data['target'] = y_train.values\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DATOS DE REFERENCIA (BASELINE)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Forma: {reference_data.shape}\")\n",
    "print(f\"Features: {len(feature_names)}\")\n",
    "print(f\"\\nPrimeras filas:\")\n",
    "print(reference_data.head())\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0c38da",
   "metadata": {},
   "source": [
    "## 4. Simular Datos de Producci√≥n con Drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6b779d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n para simular drift en datos\n",
    "def simulate_production_data_with_drift(reference_df, drift_magnitude=0.2, sample_size=None):\n",
    "    \"\"\"\n",
    "    Simula datos de producci√≥n con drift artificial.\n",
    "    \n",
    "    Args:\n",
    "        reference_df: DataFrame de referencia (training data)\n",
    "        drift_magnitude: Magnitud del drift (0.0 a 1.0)\n",
    "        sample_size: Tama√±o de la muestra (None = mismo tama√±o que referencia)\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame con datos simulados con drift\n",
    "    \"\"\"\n",
    "    if sample_size is None:\n",
    "        sample_size = len(reference_df)\n",
    "    \n",
    "    # Tomar muestra del test set\n",
    "    production_data = reference_df.sample(n=min(sample_size, len(reference_df)), \n",
    "                                         replace=True, \n",
    "                                         random_state=42).copy()\n",
    "    \n",
    "    # Aplicar drift a features num√©ricos\n",
    "    numeric_cols = production_data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    if 'target' in numeric_cols:\n",
    "        numeric_cols.remove('target')\n",
    "    \n",
    "    for col in numeric_cols:\n",
    "        # Agregar sesgo (shift) y escala (scale)\n",
    "        mean_shift = reference_df[col].mean() * drift_magnitude\n",
    "        scale_factor = 1 + (drift_magnitude * 0.5)\n",
    "        \n",
    "        # Aplicar transformaci√≥n con probabilidad basada en drift_magnitude\n",
    "        mask = np.random.random(len(production_data)) < drift_magnitude\n",
    "        production_data.loc[mask, col] = (\n",
    "            production_data.loc[mask, col] * scale_factor + mean_shift\n",
    "        )\n",
    "    \n",
    "    return production_data\n",
    "\n",
    "# Simular diferentes escenarios de drift\n",
    "print(\"=\" * 80)\n",
    "print(\"SIMULACI√ìN DE DATOS DE PRODUCCI√ìN\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Escenario 1: Sin drift (datos similares a entrenamiento)\n",
    "current_data_no_drift = simulate_production_data_with_drift(\n",
    "    reference_data, \n",
    "    drift_magnitude=0.0,\n",
    "    sample_size=1000\n",
    ")\n",
    "print(f\"\\n‚úì Escenario 1: Sin drift - {current_data_no_drift.shape[0]} registros\")\n",
    "\n",
    "# Escenario 2: Drift moderado\n",
    "current_data_moderate = simulate_production_data_with_drift(\n",
    "    reference_data, \n",
    "    drift_magnitude=0.3,\n",
    "    sample_size=1000\n",
    ")\n",
    "print(f\"‚úì Escenario 2: Drift moderado (30%) - {current_data_moderate.shape[0]} registros\")\n",
    "\n",
    "# Escenario 3: Drift severo\n",
    "current_data_severe = simulate_production_data_with_drift(\n",
    "    reference_data, \n",
    "    drift_magnitude=0.6,\n",
    "    sample_size=1000\n",
    ")\n",
    "print(f\"‚úì Escenario 3: Drift severo (60%) - {current_data_severe.shape[0]} registros\")\n",
    "\n",
    "# Usar escenario moderado para el an√°lisis principal\n",
    "current_data = current_data_moderate.copy()\n",
    "\n",
    "print(f\"\\n‚úì Datos actuales para monitoreo: {current_data.shape}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2ad90d",
   "metadata": {},
   "source": [
    "## 5. Tests Estad√≠sticos de Data Drift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa23854",
   "metadata": {},
   "source": [
    "### 5.1 Kolmogorov-Smirnov Test (Variables Num√©ricas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5e7871",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kolmogorov_smirnov_test(reference_data, current_data, feature, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Test de Kolmogorov-Smirnov para detectar drift en variables num√©ricas.\n",
    "    \n",
    "    H0: Las dos muestras provienen de la misma distribuci√≥n\n",
    "    H1: Las muestras provienen de distribuciones diferentes\n",
    "    \n",
    "    Returns:\n",
    "        dict: estad√≠stico KS, p-value, drift detectado\n",
    "    \"\"\"\n",
    "    statistic, p_value = ks_2samp(reference_data[feature], current_data[feature])\n",
    "    \n",
    "    return {\n",
    "        'feature': feature,\n",
    "        'ks_statistic': statistic,\n",
    "        'p_value': p_value,\n",
    "        'drift_detected': p_value < alpha,\n",
    "        'test': 'Kolmogorov-Smirnov'\n",
    "    }\n",
    "\n",
    "# Aplicar KS test a todas las variables num√©ricas\n",
    "numeric_features = reference_data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "if 'target' in numeric_features:\n",
    "    numeric_features.remove('target')\n",
    "\n",
    "ks_results = []\n",
    "for feature in numeric_features:\n",
    "    result = kolmogorov_smirnov_test(reference_data, current_data, feature)\n",
    "    ks_results.append(result)\n",
    "\n",
    "# Crear DataFrame de resultados\n",
    "ks_df = pd.DataFrame(ks_results)\n",
    "ks_df = ks_df.sort_values('ks_statistic', ascending=False)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"KOLMOGOROV-SMIRNOV TEST RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nTotal features analizados: {len(ks_df)}\")\n",
    "print(f\"Features con drift detectado (p < 0.05): {ks_df['drift_detected'].sum()}\")\n",
    "print(f\"\\nTop 10 features con mayor KS statistic:\")\n",
    "print(ks_df.head(10)[['feature', 'ks_statistic', 'p_value', 'drift_detected']].to_string(index=False))\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3191d0a4",
   "metadata": {},
   "source": [
    "### 5.2 Population Stability Index (PSI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c246014c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_psi(reference_data, current_data, feature, bins=10):\n",
    "    \"\"\"\n",
    "    Calcula el Population Stability Index (PSI).\n",
    "    \n",
    "    PSI < 0.1: No drift significativo\n",
    "    0.1 <= PSI < 0.2: Drift moderado\n",
    "    PSI >= 0.2: Drift significativo\n",
    "    \n",
    "    Returns:\n",
    "        dict: PSI value, interpretaci√≥n\n",
    "    \"\"\"\n",
    "    # Definir bins basados en datos de referencia\n",
    "    breakpoints = np.quantile(reference_data[feature], np.linspace(0, 1, bins + 1))\n",
    "    breakpoints = np.unique(breakpoints)  # Eliminar duplicados\n",
    "    \n",
    "    # Calcular distribuciones\n",
    "    ref_counts, _ = np.histogram(reference_data[feature], bins=breakpoints)\n",
    "    curr_counts, _ = np.histogram(current_data[feature], bins=breakpoints)\n",
    "    \n",
    "    # Convertir a proporciones\n",
    "    ref_props = ref_counts / len(reference_data)\n",
    "    curr_props = curr_counts / len(current_data)\n",
    "    \n",
    "    # Evitar divisi√≥n por cero\n",
    "    ref_props = np.where(ref_props == 0, 0.0001, ref_props)\n",
    "    curr_props = np.where(curr_props == 0, 0.0001, curr_props)\n",
    "    \n",
    "    # Calcular PSI\n",
    "    psi_value = np.sum((curr_props - ref_props) * np.log(curr_props / ref_props))\n",
    "    \n",
    "    # Interpretaci√≥n\n",
    "    if psi_value < 0.1:\n",
    "        interpretation = 'Sin drift'\n",
    "    elif psi_value < 0.2:\n",
    "        interpretation = 'Drift moderado'\n",
    "    else:\n",
    "        interpretation = 'Drift significativo'\n",
    "    \n",
    "    return {\n",
    "        'feature': feature,\n",
    "        'psi': psi_value,\n",
    "        'interpretation': interpretation,\n",
    "        'test': 'PSI'\n",
    "    }\n",
    "\n",
    "# Calcular PSI para todas las variables num√©ricas\n",
    "psi_results = []\n",
    "for feature in numeric_features:\n",
    "    result = calculate_psi(reference_data, current_data, feature)\n",
    "    psi_results.append(result)\n",
    "\n",
    "psi_df = pd.DataFrame(psi_results)\n",
    "psi_df = psi_df.sort_values('psi', ascending=False)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"POPULATION STABILITY INDEX (PSI) RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nTotal features analizados: {len(psi_df)}\")\n",
    "print(f\"Features sin drift (PSI < 0.1): {(psi_df['psi'] < 0.1).sum()}\")\n",
    "print(f\"Features con drift moderado (0.1 <= PSI < 0.2): {((psi_df['psi'] >= 0.1) & (psi_df['psi'] < 0.2)).sum()}\")\n",
    "print(f\"Features con drift significativo (PSI >= 0.2): {(psi_df['psi'] >= 0.2).sum()}\")\n",
    "print(f\"\\nTop 10 features con mayor PSI:\")\n",
    "print(psi_df.head(10)[['feature', 'psi', 'interpretation']].to_string(index=False))\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb75ed20",
   "metadata": {},
   "source": [
    "### 5.3 Jensen-Shannon Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583f3c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_jensen_shannon(reference_data, current_data, feature, bins=50):\n",
    "    \"\"\"\n",
    "    Calcula la divergencia de Jensen-Shannon entre dos distribuciones.\n",
    "    \n",
    "    JS = 0: Distribuciones id√©nticas\n",
    "    JS = 1: Distribuciones completamente diferentes\n",
    "    \n",
    "    Returns:\n",
    "        dict: JS divergence, interpretaci√≥n\n",
    "    \"\"\"\n",
    "    # Definir rango com√∫n\n",
    "    min_val = min(reference_data[feature].min(), current_data[feature].min())\n",
    "    max_val = max(reference_data[feature].max(), current_data[feature].max())\n",
    "    bins_range = np.linspace(min_val, max_val, bins + 1)\n",
    "    \n",
    "    # Calcular distribuciones\n",
    "    ref_hist, _ = np.histogram(reference_data[feature], bins=bins_range, density=True)\n",
    "    curr_hist, _ = np.histogram(current_data[feature], bins=bins_range, density=True)\n",
    "    \n",
    "    # Normalizar para que sumen 1\n",
    "    ref_hist = ref_hist / ref_hist.sum()\n",
    "    curr_hist = curr_hist / curr_hist.sum()\n",
    "    \n",
    "    # Evitar valores cero\n",
    "    ref_hist = np.where(ref_hist == 0, 1e-10, ref_hist)\n",
    "    curr_hist = np.where(curr_hist == 0, 1e-10, curr_hist)\n",
    "    \n",
    "    # Calcular JS divergence\n",
    "    js_div = jensenshannon(ref_hist, curr_hist)\n",
    "    \n",
    "    # Interpretaci√≥n\n",
    "    if js_div < 0.1:\n",
    "        interpretation = 'Sin drift'\n",
    "    elif js_div < 0.3:\n",
    "        interpretation = 'Drift moderado'\n",
    "    else:\n",
    "        interpretation = 'Drift significativo'\n",
    "    \n",
    "    return {\n",
    "        'feature': feature,\n",
    "        'js_divergence': js_div,\n",
    "        'interpretation': interpretation,\n",
    "        'test': 'Jensen-Shannon'\n",
    "    }\n",
    "\n",
    "# Calcular JS divergence para todas las variables num√©ricas\n",
    "js_results = []\n",
    "for feature in numeric_features:\n",
    "    result = calculate_jensen_shannon(reference_data, current_data, feature)\n",
    "    js_results.append(result)\n",
    "\n",
    "js_df = pd.DataFrame(js_results)\n",
    "js_df = js_df.sort_values('js_divergence', ascending=False)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"JENSEN-SHANNON DIVERGENCE RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nTotal features analizados: {len(js_df)}\")\n",
    "print(f\"Features sin drift (JS < 0.1): {(js_df['js_divergence'] < 0.1).sum()}\")\n",
    "print(f\"Features con drift moderado (0.1 <= JS < 0.3): {((js_df['js_divergence'] >= 0.1) & (js_df['js_divergence'] < 0.3)).sum()}\")\n",
    "print(f\"Features con drift significativo (JS >= 0.3): {(js_df['js_divergence'] >= 0.3).sum()}\")\n",
    "print(f\"\\nTop 10 features con mayor JS divergence:\")\n",
    "print(js_df.head(10)[['feature', 'js_divergence', 'interpretation']].to_string(index=False))\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48629979",
   "metadata": {},
   "source": [
    "### 5.4 Chi-Cuadrado Test (Variables Categ√≥ricas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171d123b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi_square_test(reference_data, current_data, feature, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Test Chi-cuadrado para variables categ√≥ricas.\n",
    "    \n",
    "    H0: No hay diferencia en las distribuciones de categor√≠as\n",
    "    H1: Hay diferencia significativa\n",
    "    \n",
    "    Returns:\n",
    "        dict: chi2 statistic, p-value, drift detectado\n",
    "    \"\"\"\n",
    "    # Obtener conteos de categor√≠as\n",
    "    ref_counts = reference_data[feature].value_counts().sort_index()\n",
    "    curr_counts = current_data[feature].value_counts().sort_index()\n",
    "    \n",
    "    # Alinear categor√≠as\n",
    "    all_categories = sorted(set(ref_counts.index) | set(curr_counts.index))\n",
    "    ref_counts = ref_counts.reindex(all_categories, fill_value=0)\n",
    "    curr_counts = curr_counts.reindex(all_categories, fill_value=0)\n",
    "    \n",
    "    # Crear tabla de contingencia\n",
    "    contingency_table = np.array([ref_counts.values, curr_counts.values])\n",
    "    \n",
    "    # Realizar test chi-cuadrado\n",
    "    chi2_stat, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "    \n",
    "    return {\n",
    "        'feature': feature,\n",
    "        'chi2_statistic': chi2_stat,\n",
    "        'p_value': p_value,\n",
    "        'drift_detected': p_value < alpha,\n",
    "        'test': 'Chi-cuadrado'\n",
    "    }\n",
    "\n",
    "# Identificar variables categ√≥ricas\n",
    "categorical_features = reference_data.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "if len(categorical_features) > 0:\n",
    "    chi2_results = []\n",
    "    for feature in categorical_features:\n",
    "        result = chi_square_test(reference_data, current_data, feature)\n",
    "        chi2_results.append(result)\n",
    "    \n",
    "    chi2_df = pd.DataFrame(chi2_results)\n",
    "    chi2_df = chi2_df.sort_values('chi2_statistic', ascending=False)\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"CHI-CUADRADO TEST RESULTS (Variables Categ√≥ricas)\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"\\nTotal features categ√≥ricos analizados: {len(chi2_df)}\")\n",
    "    print(f\"Features con drift detectado (p < 0.05): {chi2_df['drift_detected'].sum()}\")\n",
    "    print(f\"\\nResultados:\")\n",
    "    print(chi2_df[['feature', 'chi2_statistic', 'p_value', 'drift_detected']].to_string(index=False))\n",
    "    print(\"=\" * 80)\n",
    "else:\n",
    "    print(\"No se encontraron variables categ√≥ricas en el dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73862395",
   "metadata": {},
   "source": [
    "## 6. Resumen Consolidado de Drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ff867c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consolidar resultados de todos los tests\n",
    "drift_summary = pd.merge(\n",
    "    ks_df[['feature', 'ks_statistic', 'drift_detected']].rename(columns={'drift_detected': 'ks_drift'}),\n",
    "    psi_df[['feature', 'psi', 'interpretation']].rename(columns={'interpretation': 'psi_status'}),\n",
    "    on='feature'\n",
    ")\n",
    "\n",
    "drift_summary = pd.merge(\n",
    "    drift_summary,\n",
    "    js_df[['feature', 'js_divergence']],\n",
    "    on='feature'\n",
    ")\n",
    "\n",
    "# Calcular score de drift (0-100)\n",
    "drift_summary['drift_score'] = (\n",
    "    drift_summary['ks_drift'].astype(int) * 20 +  # 20 puntos si KS detecta drift\n",
    "    (drift_summary['psi'] * 100).clip(0, 40) +     # Hasta 40 puntos por PSI\n",
    "    (drift_summary['js_divergence'] * 100).clip(0, 40)  # Hasta 40 puntos por JS\n",
    ")\n",
    "\n",
    "# Clasificaci√≥n de riesgo\n",
    "def classify_risk(score):\n",
    "    if score < 25:\n",
    "        return 'üü¢ Bajo'\n",
    "    elif score < 50:\n",
    "        return 'üü° Moderado'\n",
    "    elif score < 75:\n",
    "        return 'üü† Alto'\n",
    "    else:\n",
    "        return 'üî¥ Cr√≠tico'\n",
    "\n",
    "drift_summary['risk_level'] = drift_summary['drift_score'].apply(classify_risk)\n",
    "drift_summary = drift_summary.sort_values('drift_score', ascending=False)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"RESUMEN CONSOLIDADO DE DATA DRIFT\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nTotal features monitoreados: {len(drift_summary)}\")\n",
    "print(f\"\\nDistribuci√≥n de riesgo:\")\n",
    "print(drift_summary['risk_level'].value_counts().to_string())\n",
    "print(f\"\\nTop 10 features con mayor drift:\")\n",
    "print(drift_summary.head(10)[['feature', 'drift_score', 'risk_level', 'psi_status']].to_string(index=False))\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "# Guardar resumen\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "summary_file = os.path.join(MONITORING_DIR, f'drift_summary_{timestamp}.csv')\n",
    "drift_summary.to_csv(summary_file, index=False)\n",
    "print(f\"\\n‚úì Resumen guardado: {summary_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac9c22a",
   "metadata": {},
   "source": [
    "## 7. Visualizaciones de Drift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8584bb",
   "metadata": {},
   "source": [
    "### 7.1 Dashboard de M√©tricas de Drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4bc9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear dashboard con m√©tricas principales\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=(\n",
    "        'Distribuci√≥n de Riesgo por Feature',\n",
    "        'Top 10 Features con Mayor Drift Score',\n",
    "        'PSI Distribution',\n",
    "        'Jensen-Shannon Divergence Distribution'\n",
    "    ),\n",
    "    specs=[\n",
    "        [{'type': 'pie'}, {'type': 'bar'}],\n",
    "        [{'type': 'histogram'}, {'type': 'histogram'}]\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 1. Pie chart de distribuci√≥n de riesgo\n",
    "risk_counts = drift_summary['risk_level'].value_counts()\n",
    "fig.add_trace(\n",
    "    go.Pie(labels=risk_counts.index, values=risk_counts.values, \n",
    "           marker=dict(colors=['green', 'yellow', 'orange', 'red'])),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# 2. Bar chart de top 10 features\n",
    "top_10 = drift_summary.head(10)\n",
    "fig.add_trace(\n",
    "    go.Bar(x=top_10['feature'], y=top_10['drift_score'],\n",
    "           marker=dict(color=top_10['drift_score'], colorscale='Reds')),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# 3. Histograma de PSI\n",
    "fig.add_trace(\n",
    "    go.Histogram(x=drift_summary['psi'], nbinsx=30, name='PSI'),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# 4. Histograma de JS divergence\n",
    "fig.add_trace(\n",
    "    go.Histogram(x=drift_summary['js_divergence'], nbinsx=30, name='JS Div'),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "fig.update_layout(height=800, showlegend=False, title_text=\"Data Drift Monitoring Dashboard\")\n",
    "fig.show()\n",
    "\n",
    "# Guardar figura\n",
    "fig.write_html(os.path.join(MONITORING_DIR, f'drift_dashboard_{timestamp}.html'))\n",
    "print(f\"‚úì Dashboard guardado: drift_dashboard_{timestamp}.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35dc7849",
   "metadata": {},
   "source": [
    "### 7.2 Comparaci√≥n de Distribuciones (Top 6 Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edad9e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar distribuciones de los features con mayor drift\n",
    "top_drift_features = drift_summary.head(6)['feature'].tolist()\n",
    "\n",
    "fig, axes = plt.subplots(3, 2, figsize=(15, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, feature in enumerate(top_drift_features):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Histogramas superpuestos\n",
    "    ax.hist(reference_data[feature], bins=50, alpha=0.5, label='Reference (Training)', \n",
    "            color='blue', density=True)\n",
    "    ax.hist(current_data[feature], bins=50, alpha=0.5, label='Current (Production)', \n",
    "            color='red', density=True)\n",
    "    \n",
    "    # Obtener m√©tricas de drift para el feature\n",
    "    feature_drift = drift_summary[drift_summary['feature'] == feature].iloc[0]\n",
    "    \n",
    "    ax.set_title(f\"{feature}\\nDrift Score: {feature_drift['drift_score']:.1f} | {feature_drift['risk_level']}\")\n",
    "    ax.set_xlabel(feature)\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(MONITORING_DIR, f'distribution_comparison_{timestamp}.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚úì Gr√°fico de distribuciones guardado: distribution_comparison_{timestamp}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb8e9e0",
   "metadata": {},
   "source": [
    "## 8. Reporte con Evidently AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24925d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar reporte completo con Evidently\n",
    "data_drift_report = Report(metrics=[\n",
    "    DataDriftPreset(),\n",
    "    DataQualityPreset()\n",
    "])\n",
    "\n",
    "# Preparar datos para Evidently (sin target para evitar warnings)\n",
    "reference_for_evidently = reference_data.drop(columns=['target'])\n",
    "current_for_evidently = current_data.drop(columns=['target'])\n",
    "\n",
    "# Ejecutar reporte\n",
    "data_drift_report.run(\n",
    "    reference_data=reference_for_evidently,\n",
    "    current_data=current_for_evidently\n",
    ")\n",
    "\n",
    "# Guardar reporte HTML\n",
    "evidently_report_path = os.path.join(MONITORING_DIR, f'evidently_report_{timestamp}.html')\n",
    "data_drift_report.save_html(evidently_report_path)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"REPORTE EVIDENTLY AI GENERADO\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Archivo: {evidently_report_path}\")\n",
    "print(f\"\\nEl reporte incluye:\")\n",
    "print(\"  ‚Ä¢ Data Drift Preset: An√°lisis completo de drift por feature\")\n",
    "print(\"  ‚Ä¢ Data Quality Preset: M√©tricas de calidad de datos\")\n",
    "print(\"  ‚Ä¢ Visualizaciones interactivas\")\n",
    "print(\"  ‚Ä¢ Tests estad√≠sticos autom√°ticos\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d742f9a",
   "metadata": {},
   "source": [
    "## 9. Sistema de Alertas y Recomendaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0460cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir umbrales de alerta\n",
    "THRESHOLDS = {\n",
    "    'critical': 75,  # Drift score cr√≠tico\n",
    "    'high': 50,      # Drift score alto\n",
    "    'moderate': 25   # Drift score moderado\n",
    "}\n",
    "\n",
    "# Generar alertas\n",
    "def generate_alerts(drift_summary, thresholds):\n",
    "    \"\"\"\n",
    "    Genera alertas basadas en umbrales de drift.\n",
    "    \"\"\"\n",
    "    alerts = []\n",
    "    \n",
    "    # Contar features por nivel de riesgo\n",
    "    critical_features = drift_summary[drift_summary['drift_score'] >= thresholds['critical']]\n",
    "    high_features = drift_summary[\n",
    "        (drift_summary['drift_score'] >= thresholds['high']) & \n",
    "        (drift_summary['drift_score'] < thresholds['critical'])\n",
    "    ]\n",
    "    moderate_features = drift_summary[\n",
    "        (drift_summary['drift_score'] >= thresholds['moderate']) & \n",
    "        (drift_summary['drift_score'] < thresholds['high'])\n",
    "    ]\n",
    "    \n",
    "    # Alerta cr√≠tica\n",
    "    if len(critical_features) > 0:\n",
    "        alerts.append({\n",
    "            'level': 'üî¥ CR√çTICO',\n",
    "            'message': f'{len(critical_features)} features con drift cr√≠tico detectado',\n",
    "            'features': critical_features['feature'].tolist()[:5],  # Top 5\n",
    "            'recommendation': 'REENTRENAMIENTO INMEDIATO DEL MODELO REQUERIDO'\n",
    "        })\n",
    "    \n",
    "    # Alerta alta\n",
    "    if len(high_features) > 0:\n",
    "        alerts.append({\n",
    "            'level': 'üü† ALTO',\n",
    "            'message': f'{len(high_features)} features con drift alto detectado',\n",
    "            'features': high_features['feature'].tolist()[:5],\n",
    "            'recommendation': 'Planificar reentrenamiento del modelo en los pr√≥ximos 7 d√≠as'\n",
    "        })\n",
    "    \n",
    "    # Alerta moderada\n",
    "    if len(moderate_features) > 0:\n",
    "        alerts.append({\n",
    "            'level': 'üü° MODERADO',\n",
    "            'message': f'{len(moderate_features)} features con drift moderado detectado',\n",
    "            'features': moderate_features['feature'].tolist()[:5],\n",
    "            'recommendation': 'Monitorear continuamente. Considerar reentrenamiento si persiste'\n",
    "        })\n",
    "    \n",
    "    # Sin alertas\n",
    "    if len(alerts) == 0:\n",
    "        alerts.append({\n",
    "            'level': 'üü¢ NORMAL',\n",
    "            'message': 'No se detect√≥ drift significativo',\n",
    "            'features': [],\n",
    "            'recommendation': 'Modelo operando normalmente. Continuar monitoreo'\n",
    "        })\n",
    "    \n",
    "    return alerts\n",
    "\n",
    "# Generar alertas\n",
    "alerts = generate_alerts(drift_summary, THRESHOLDS)\n",
    "\n",
    "# Mostrar alertas\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üö® SISTEMA DE ALERTAS - DATA DRIFT MONITORING\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Total features monitoreados: {len(drift_summary)}\")\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "\n",
    "for alert in alerts:\n",
    "    print(f\"\\n{alert['level']}: {alert['message']}\")\n",
    "    if alert['features']:\n",
    "        print(f\"Features afectados: {', '.join(alert['features'])}\")\n",
    "    print(f\"Recomendaci√≥n: {alert['recommendation']}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "# Guardar alertas en JSON\n",
    "alerts_file = os.path.join(MONITORING_DIR, f'alerts_{timestamp}.json')\n",
    "import json\n",
    "with open(alerts_file, 'w') as f:\n",
    "    json.dump({\n",
    "        'timestamp': timestamp,\n",
    "        'total_features': len(drift_summary),\n",
    "        'alerts': alerts\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(f\"\\n‚úì Alertas guardadas: {alerts_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1102fd",
   "metadata": {},
   "source": [
    "## 10. Conclusiones del Monitoreo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea6a622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumen final del monitoreo\n",
    "print(\"=\" * 80)\n",
    "print(\"üìä CONCLUSIONES DEL MONITOREO DE DATA DRIFT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Estad√≠sticas generales\n",
    "total_features = len(drift_summary)\n",
    "features_with_drift = len(drift_summary[drift_summary['drift_score'] >= THRESHOLDS['moderate']])\n",
    "drift_percentage = (features_with_drift / total_features) * 100\n",
    "\n",
    "print(f\"\\n1. ESTAD√çSTICAS GENERALES:\")\n",
    "print(f\"   ‚Ä¢ Total de features monitoreados: {total_features}\")\n",
    "print(f\"   ‚Ä¢ Features con drift detectado: {features_with_drift} ({drift_percentage:.1f}%)\")\n",
    "print(f\"   ‚Ä¢ Features sin drift: {total_features - features_with_drift}\")\n",
    "\n",
    "print(f\"\\n2. DISTRIBUCI√ìN POR NIVEL DE RIESGO:\")\n",
    "for level in drift_summary['risk_level'].value_counts().sort_index():\n",
    "    count = drift_summary['risk_level'].value_counts()[level]\n",
    "    percentage = (count / total_features) * 100\n",
    "    print(f\"   ‚Ä¢ {level}: {count} features ({percentage:.1f}%)\")\n",
    "\n",
    "print(f\"\\n3. M√âTRICAS PROMEDIO:\")\n",
    "print(f\"   ‚Ä¢ PSI promedio: {drift_summary['psi'].mean():.4f}\")\n",
    "print(f\"   ‚Ä¢ JS Divergence promedio: {drift_summary['js_divergence'].mean():.4f}\")\n",
    "print(f\"   ‚Ä¢ Drift Score promedio: {drift_summary['drift_score'].mean():.2f}\")\n",
    "\n",
    "print(f\"\\n4. TOP 5 FEATURES CON MAYOR DRIFT:\")\n",
    "for idx, row in drift_summary.head(5).iterrows():\n",
    "    print(f\"   {idx+1}. {row['feature']}: Score={row['drift_score']:.1f} ({row['risk_level']})\")\n",
    "\n",
    "print(f\"\\n5. RECOMENDACI√ìN FINAL:\")\n",
    "if drift_summary['drift_score'].max() >= THRESHOLDS['critical']:\n",
    "    print(\"   üî¥ ACCI√ìN REQUERIDA: Reentrenar el modelo INMEDIATAMENTE\")\n",
    "    print(\"      Drift cr√≠tico detectado que compromete la precisi√≥n del modelo.\")\n",
    "elif drift_summary['drift_score'].max() >= THRESHOLDS['high']:\n",
    "    print(\"   üü† ALERTA: Planificar reentrenamiento en corto plazo (7 d√≠as)\")\n",
    "    print(\"      Drift significativo detectado. Monitorear continuamente.\")\n",
    "elif drift_summary['drift_score'].max() >= THRESHOLDS['moderate']:\n",
    "    print(\"   üü° ADVERTENCIA: Monitorear de cerca\")\n",
    "    print(\"      Drift moderado. Evaluar reentrenamiento si persiste.\")\n",
    "else:\n",
    "    print(\"   üü¢ NORMAL: Modelo operando correctamente\")\n",
    "    print(\"      No se detect√≥ drift significativo. Continuar monitoreo regular.\")\n",
    "\n",
    "print(f\"\\n6. ARCHIVOS GENERADOS:\")\n",
    "print(f\"   ‚Ä¢ Resumen CSV: drift_summary_{timestamp}.csv\")\n",
    "print(f\"   ‚Ä¢ Dashboard HTML: drift_dashboard_{timestamp}.html\")\n",
    "print(f\"   ‚Ä¢ Reporte Evidently: evidently_report_{timestamp}.html\")\n",
    "print(f\"   ‚Ä¢ Alertas JSON: alerts_{timestamp}.json\")\n",
    "print(f\"   ‚Ä¢ Distribuciones PNG: distribution_comparison_{timestamp}.png\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úì Monitoreo completado exitosamente\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
